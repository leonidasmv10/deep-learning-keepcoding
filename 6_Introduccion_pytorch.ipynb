{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento y Transfer Learning con Redes Neuronales en PyTorch\n",
        "\n",
        "Este notebook describe la implementación y entrenamiento de dos arquitecturas de redes neuronales en PyTorch: una red de capas totalmente conectadas (Fully Connected) y una red AlexNet. Incluye pasos para cargar los datos, entrenar los modelos desde cero, y realizar transfer learning adaptando los modelos para el problema de clasificación en CIFAR-100."
      ],
      "metadata": {
        "id": "1WfHlq1JUCen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de Librerías"
      ],
      "metadata": {
        "id": "IK_xga9oUHuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# En Pytorch tenemos:\n",
        "# \"cuda\" -> GPU de Intel\n",
        "# \"mps\" -> MacOS  Serie M (torch.backends.mps.is_available())\n",
        "# \"cpu\" -> SIN GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r9mfpgFUKLy",
        "outputId": "af1f7e6a-1585-4f51-e5b8-b2685a534432"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta primera sección, importamos todas las librerías y módulos necesarios para construir, entrenar y evaluar nuestras redes neuronales en PyTorch. Aquí:\n",
        "\n",
        "- `torch`, `torch.nn`, `torch.optim`: PyTorch y sus módulos principales para construir redes neuronales y optimización.\n",
        "- `torchvision`: Módulo que permite trabajar con datasets y transformaciones de imágenes.\n",
        "- `tqdm`: Herramienta para mostrar barras de progreso durante el entrenamiento del modelo.\n"
      ],
      "metadata": {
        "id": "ch0S2fwPUNbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de la Red Neuronal Fully Connected"
      ],
      "metadata": {
        "id": "Ac50mY98UYhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedNet(nn.Module):\n",
        "    def __init__(self, input_size=224*224*3, hidden1=1024, hidden2=512, num_classes=1000):\n",
        "        super(FullyConnectedNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        x = self.dropout(torch.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BkhWrrf6Ubxx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta sección define una red neuronal `FullyConnectedNet`, que tiene:\n",
        "\n",
        "- Una capa de entrada que aplana la imagen (`Flatten`).\n",
        "- Tres capas lineales, también llamadas Densas (`Linear`), cada una seguida por una capa de activación `ReLU` y `Dropout` para prevenir el sobreajuste.\n",
        "- La última capa tiene `num_classes` neuronas, que se utiliza para la clasificación en una salida de tamaño 1000 (número de clases de ImageNet)."
      ],
      "metadata": {
        "id": "_4Cp3hwWUcra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de la Arquitectura AlexNet"
      ],
      "metadata": {
        "id": "rSDVL3P3Uqy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6) # equivalente a reshape\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "aRbRO5gzUrpM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta clase implementa el modelo AlexNet, una arquitectura de red neuronal convolucional (CNN) para clasificación de imágenes. Consiste en dos bloques principales:\n",
        "\n",
        "- Bloque de características (`features`): Convoluciones y capas de pooling para extraer características.\n",
        "- Bloque de clasificación (`classifier`): Compuesto de capas totalmente conectadas con Dropout para reducir el sobreajuste."
      ],
      "metadata": {
        "id": "Rd2qMBK2UtkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargador de Datos para CIFAR-10"
      ],
      "metadata": {
        "id": "l75xFXkJU0z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    train_dataset = datasets.CIFAR10(root='./CIFAR10/', train=True, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    return train_loader"
      ],
      "metadata": {
        "id": "M2i5ELeLU25_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta función prepara los datos para el entrenamiento:\n",
        "\n",
        "- Aplica una serie de transformaciones a las imágenes (ajuste de tamaño, recorte, normalización).\n",
        "- Utiliza el dataset CIFAR-10 como fuente de imágenes.\n",
        "- Retorna un DataLoader para iterar por lotes de datos.\n",
        "\n",
        "Podemos utilizar esta función porque CIFAR-10 es un dataset que ya está incluido dentro del paquete Pytorch. Si quisiéramos emplear un dataset propio, tendríamos que programar el mecanismo de carga de datos por nuestros propios medios:\n",
        "\n",
        "1. En Pytorch, esto se logra mediante la combinación de un `torch.utils.data.Dataset` y de un `torch.utils.data.DataLoader`. Mientras que el primero se encarga de cargar en memoria los datos y leerlos, el segundo objeto se va a encargar de cargar en batches esos datos para que podamos usarlos de input en nuestras redes neuronales.\n",
        "2. Los `Dataset` deben tener mínimo 3 funciones: `__init__` para inicializar la clase (esto es, definir dónde están los datos; pueden ser listas de textos, listas de *paths* a ficheros de imágenes, o una tabla), `__len__` para poder determinar el tamaño del dataset, y `__getitem__` para poder extraer del dataset el elemento de índice `idx` (esto es, poder indexar las muestras del dataset).\n",
        "\n",
        "Por ejemplo, imaginad que nuestro dataset se compone de\n",
        "- Input: Imágenes, guardadas en nuestro ordenador en la carpeta `fotos_Cancún`.\n",
        "- Output: Una lista de `0` y `1` indicando si en cada foto sonreímos o no.\n"
      ],
      "metadata": {
        "id": "f5SFhEHkU5Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Representa un ejemplo rapido de dataset para un problema donde las imagenes,\n",
        "    guardadas en un carpeta, tienen asignada cada una una etiqueta binaria.\n",
        "    \"\"\"\n",
        "    def __init__(self, imgs_paths: list[str], labels: list[int]):\n",
        "        self.images = imgs_paths\n",
        "        self.labels = labels\n",
        "        assert len(imgs_paths) == len(labels), \"The number of images and labels must be the same.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# imaginamos nuestra carpeta, extraemos los ficheros de las fotos\n",
        "photos = list(Path(\"./fotos_Cancún/\").glob(\"*.png\"))\n",
        "# las etiquetas imaginamos que las hemos cargado de algún fichero o tabla\n",
        "labels = [0, 1, 0, 1, 1, ...]\n",
        "\n",
        "cancun_dataset = OurDataset(photos, labels)\n",
        "cancun_dataloader = DataLoader(cancun_dataset, batch_size=8, shuffle=False)\n",
        "# si hacemos cancun_dataset[0],\n",
        "# >>> \"./fotos_Cancun/photo_0.png\", 0"
      ],
      "metadata": {
        "id": "nsp-fpvTSIcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto no sería suficiente, por el siguiente detalle: Daos cuenta de que al extraer el elemento `idx` en la función `__getitem__`, no estamos realmente cargando la imagen, sino el path a la imagen. Para verdaderamente cargar una imagen (además de poder incluir cualquier tipo de preprocesamiento *online*) debemos definir una función adicional. Por tanto,\n"
      ],
      "metadata": {
        "id": "z7Tg7rd-UM9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def load_photo(path):\n",
        "  # podemos complicar esta funcion todo lo que deseemos\n",
        "  return cv2.imread(path).cvtColor(cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "class OurDataset(torch.utils.data.Dataset):\n",
        "    \"\"\" Representa un ejemplo rapido de dataset para un problema donde las imagenes,\n",
        "    guardadas en un carpeta, tienen asignada cada una una etiqueta binaria.\n",
        "    \"\"\"\n",
        "    def __init__(self, imgs_paths: list[str], labels: list[int]):\n",
        "        self.paths = imgs_paths\n",
        "        self.labels = labels\n",
        "        assert len(imgs_paths) == len(labels), \"The number of images and labels must be the same.\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return load_photo(self.paths[idx]), self.labels[idx]\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# imaginamos nuestra carpeta, extraemos los ficheros de las fotos\n",
        "photos = list(Path(\"./fotos_Cancún/\").glob(\"*.png\"))\n",
        "# las etiquetas imaginamos que las hemos cargado de algún fichero o tabla\n",
        "labels = [0, 1, 0, 1, 1, ...]\n",
        "\n",
        "cancun_dataset = OurDataset(photos, labels)\n",
        "\n",
        "# si hacemos ahora cancun_dataset[0]\n",
        "# >>> np.ndarray de imagen, 0"
      ],
      "metadata": {
        "id": "vaTV0-baUiKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para pasar de este dataset donde podemos extraer muestras una a una a un procesador de carga de imágenes por batches de manera automática,"
      ],
      "metadata": {
        "id": "I0SVdHqCVYYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(cancun_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "X_eEsI-8Vh04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los `DataLoader` funcionan como un iterador en Python, de tal manera que no podemos hacer `loader[0]`, pero sí podemos iterar, obteniendo tensores del tamaño de nuestro batch size.\n",
        "\n",
        "**Recordad: Necesitaremos usar Dataset & DataLoader cuando implementemos sistemas con nuestros propios datos, es importante familiarizarse con ellos cuanto antes.**"
      ],
      "metadata": {
        "id": "Xc6qvU6kVopr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selección del Modelo"
      ],
      "metadata": {
        "id": "WPNSm0Y0VByb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_model(model_name):\n",
        "    if model_name == 'fc_net':\n",
        "        model = FullyConnectedNet()\n",
        "    elif model_name == 'alexnet':\n",
        "        model = AlexNet()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name! Choose 'fc_net' or 'alexnet'.\")\n",
        "    return model\n",
        "\n",
        "demo_model = select_model(\"alexnet\")\n",
        "print(demo_model)"
      ],
      "metadata": {
        "id": "a9_S-fZvVD6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a676dc2-60ca-499a-96f5-400e1ff17170"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_layer = demo_model.features\n",
        "print(demo_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGdMixSRR4ol",
        "outputId": "e688d66a-c15b-4551-f3ec-e41019fd298a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de Entrenamiento"
      ],
      "metadata": {
        "id": "DtktiKC8VEhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, device, epochs=10, lr=0.001):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n"
      ],
      "metadata": {
        "id": "0fFJ-9nnVHm9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la función anterior, fijaos en las pocas diferencias con respecto a Keras:\n",
        "- Diferentes nombres, pero similares.\n",
        "- Tenemos que indicar al modelo que va a tener que calcular gradientes (`model.train()`).\n",
        "- Generación de los batches por nosotros mismos mediante DataLoader.\n",
        "- Mover el modelo, así como los datos, al `device` que usemos.\n",
        "- En cada batch, olvidar el gradiente calculado anteriormente (optimizer.zero_grad()).\n",
        "- Backpropagation indicado como `loss.backward()`.\n",
        "- Siguiente paso de aprendizaje mediante `optimizer.step()`.\n",
        "\n",
        "Puede parecer un engorro comparado con Keras, pero ahora que sabemos qué significan estos conceptos, podemos tener control sobre ellos. Por ejemplo, podemos querer guardar el estado de un modelo en un instante concreto, junto con el estado de su optimizador para continuar en otro momento o en otro día con el entrenamiento (https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
      ],
      "metadata": {
        "id": "SqvcLnGVWPVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración y Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "mJRP7QdbVKHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS = 256\n",
        "MODEL = \"alexnet\"\n",
        "EPOCHS = 2\n",
        "LR = 1e-4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader = get_dataloader(BS)\n",
        "model = select_model(MODEL)\n",
        "train_model(model, train_loader, device, EPOCHS, LR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9loNDUJDVMEb",
        "outputId": "0642b6fc-7205-4c99-944d-a3fae4ddd37c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.4MB/s]\n",
            "100%|██████████| 196/196 [02:32<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.155084535783651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [02:13<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.4690938154045416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning"
      ],
      "metadata": {
        "id": "mpnQf1MfVOD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_model_for_cifar100(model, model_name):\n",
        "    if model_name == 'fc_net':\n",
        "        model.fc3 = nn.Linear(model.fc2.out_features, 100)\n",
        "    elif model_name == 'alexnet':\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 100)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name! Choose 'fc_net' or 'alexnet'.\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "X89V49w5VSg2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning y Evaluación"
      ],
      "metadata": {
        "id": "CG4ywiixVUwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar100_dataloader(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(224),          # Resize to 224x224 for compatibility\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    cifar100_train = datasets.CIFAR100(root='./CIFAR100/', train=True, transform=transform, download=True)\n",
        "    cifar100_test = datasets.CIFAR10(root='./CIFAR100/', train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(cifar100_train, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(cifar100_test, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def train_transfer_learning(model, train_loader, test_loader, device, epochs=10, lr=0.001):\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Freeze all parameters except the last layer\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Only the modified layer's parameters will require gradients\n",
        "    if hasattr(model, 'fc3'):\n",
        "        model.fc3.weight.requires_grad = True\n",
        "    else:\n",
        "        model.classifier[-1].weight.requires_grad = True\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "G6kG7817WoyE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = modify_model_for_cifar100(model, MODEL)\n",
        "train_loader, test_loader = get_cifar100_dataloader(batch_size=64)\n",
        "train_transfer_learning(model, train_loader, test_loader, device, epochs=EPOCHS, lr=LR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffkuZurlVW5q",
        "outputId": "c4468581-b50f-4c08-abd0-f489dc5fabc1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:19<00:00, 8.70MB/s]\n",
            "100%|██████████| 170M/170M [00:13<00:00, 12.3MB/s]\n",
            "100%|██████████| 782/782 [01:42<00:00,  7.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.204865190684033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [01:34<00:00,  8.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 3.987745090213883\n",
            "Test Accuracy: 0.96%\n"
          ]
        }
      ]
    }
  ]
}