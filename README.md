# Resultados y Discusi√≥n del Proyecto de Clasificaci√≥n de Lesiones Cut√°neas

Este estudio compara el rendimiento de diferentes arquitecturas de redes neuronales aplicadas a un conjunto de datos con im√°genes de lesiones dermatol√≥gicas y metadatos cl√≠nicos, como edad, sexo y localizaci√≥n.

---

# Link Google Colab

https://colab.research.google.com/drive/1g4Glragp0HndYLempEkTD31iDCrr4y9W?usp=sharing

---

## Comparativa General de Modelos

| Modelo                          | Precisi√≥n Total | F1-score Macro |
|--------------------------------|------------------|----------------|
| Modelo Tabular (Pesos)   | 0.2881           | 0.17           |
| CNN desde 0 (Pesos)        | 0.6893           | 0.53           |
| MobileNetV2 (Hyperopt + Transfer Learning + Pesos) | 0.5556       | 0.38           |
| Late Fusion (Imagen + Tabular) | 0.6287           | 0.33           |
| Early Fusion (Imagen + Tabular) | 0.2409          | 0.19           |

---

## Descripci√≥n de los Modelos

### Modelo Tabular (Hito 1)
- Utiliza √∫nicamente variables cl√≠nicas: edad, sexo, localizaci√≥n.
- T√©cnicas utilizadas:
  - Balanceo de clases con `class_weight`.
- **Desempe√±o:** muy limitado. No logra capturar patrones discriminativos suficientes.  
- üîª *Conclusi√≥n:* insuficiente informaci√≥n en variables tabulares.

---

### CNN desde cero (Hito 2)
- Red convolucional personalizada, entrenada desde cero.
- T√©cnicas utilizadas:
  - Arquitectura CNN profunda + `Dropout` + `BatchNormalization`.
  - Balanceo de clases (`class_weight`).
- **Desempe√±o:** sobresaliente para una red entrenada desde cero.
- üîº *Conclusi√≥n:* demuestra que la arquitectura CNN aprende bien sobre im√°genes, incluso sin preentrenamiento.

---

### MobileNetV2 (Transfer Learning)
- Uso de red preentrenada sobre ImageNet, con ajuste de capas superiores.
- T√©cnicas utilizadas:
  - `Transfer Learning`, `class_weight`.
- **Desempe√±o:** mejora respecto al modelo tabular, pero no supera al CNN desde cero.
- üîÅ *Conclusi√≥n:* el conocimiento previo de MobileNetV2 no se adapta perfectamente al dominio m√©dico.

---

### Late Fusion (Hito 3)
- Combinaci√≥n de dos ramas: CNN + red para datos tabulares.
- Fusiona salidas densas de ambas arquitecturas antes del clasificador.
- T√©cnicas utilizadas:
  - `class_weight` + fusi√≥n tard√≠a.
- **Desempe√±o:** muy competitivo, integrando ambas fuentes de datos.
- ‚úÖ *Conclusi√≥n:* la combinaci√≥n mejora los resultados respecto a usar solo im√°genes.

---

### Early Fusion (Hito 3)
- Im√°genes y datos tabulares fusionados antes del proceso convolucional.
- Entrenamiento sobre imagen "aplanada" + datos tabulares.
- T√©cnicas utilizadas:
  - `class_weight` + fusi√≥n temprana.
- **Desempe√±o:** el peor de todos. La informaci√≥n de imagen no se aprovecha correctamente.
- ‚ùå *Conclusi√≥n:* esta estrategia distorsiona la estructura espacial de la imagen.

---

## Conclusi√≤n

- El mejor rendimiento lo alcanza la red **CNN desde cero**, seguida por la estrategia de **Late Fusion**.
- El modelo tabular y Early Fusion son los que peores resultados ofrecen.
- El uso de MobileNetV2 aporta mejoras, pero **no garantiza mejor desempe√±o** en este contexto m√©dico espec√≠fico.
- El uso de t√©cnicas como `class_weight` y `hyperopt` fue crucial para compensar la desbalanceada distribuci√≥n de clases.

---
